0. generic assemble array routine ? (a, b, …, c, ‘’, A, B, …C, ‘’, …)
    - base this off of scipy.linalg.block_diag ... or is there
      something there already?

1. Update duf explanation in cla.apply_uf

5. Convert ext, mx, mn in DR_Results to dataframe

6. rddmig needs profiling / updating for very large DMIGs

7. add wtdmig
   - add tests
   - beta in 0.93.6

12. op4: add some c?

15. cla.py:
    DR_Results() … should this be able to init? I think so:
                   DR_Results(drdefs, mission, event)
                   … similar to DR.prepare_results(mission, event)
                   … and/or, what about a DR_Def.prepare_results()
    - actually, replace DR_Event.prepare_results() I think
                   Get rid of Info in DR_Event? Probably can’t because
                   of the uf_reds override.

    Naming convention should be more consistent:
      drdefs vs. Info vs. drminfo
         - Could they all be DR_Def instances??

         - Info can be a DR_Def instance ... but each drminfo is just
           a SimpleNamespace: a "value" in the DR_Def (or Info) dict

    - think about getting rid of DR_Event altogether ... just update
      a new DR_Def with all drdefs/dufs/ulvs's ... will this work?
      - i don't think so

    Update the code to better handle NaNs.
      - got a couple different methods going right now ... ??

    2 write complete test_cla.py
    4 when flagging, but no flags, format is shortened by one char for that column
    5 maybe add option to use only one figure ... that should be default ?
    6 y-axis label written far away in srs3/net_ifatm_0rb_eqsine_all.pdf plot ... why?
    8 Save eqsine to xlsx file

19. Add windowends to srs ?

21. In cb or cla:
    - make routine that returns string for adding data recovery
      categories for mk_net_drms output:
"""
        @cla.DR_Def.addcat
        def _():
            name = 'net_ifatm'
            ...
        ...
        """
        o   Could accept s/c name for description strings
        o   Or, make this just a function call? … that actually runs it?
            §  Would need defaults and maybe other inputs
            §  Could have it call mk_net_drms internally


23. ? Add option to change time step during simulation
    o   Save parameters in dictionary for each time step?
    o   Or, are the params cheap to recompute?
    Hmm ... would have to decide how to save results (even time steps?)


31. frf_apply_duf – see if needed and consider renaming (psd_apply_duf?)

32. cla:
    - Maybe should have capability to create null (zeros) category
      (with srs’s) … or just make sure zero case is accounted for in
      combination … hmm.

    - Form_extreme
       - Skip some events? (Like static and random, but include total)

34. cb: Teach cbtf to handle 0 frequency case like solveunc.fsolve
    does.

36. cbreorder could take tuple of matrices ...

38. test_ntfl_rbdamping: figure this out:
    pre_eig = True doesn't work ... not sure why at the
    moment (maybe conflict with rb modes setting)

39. DR.add – should check for drms and nondrms … ?
    -  What about an easier way to just proceed without nas
       (if None, more actively make do without it … with
       warning maybe?)

43. Bref – what about a model with mechanisms?
    - let bref not be a mult of 6?

48. add sparse Newmark solver

52. In rdpostop2, matrix names should probably be lower case.

53. Enhance the ‘seconct’ output (include ‘up’, ‘down’? … this is only down (I think)):

   p = op2.rdpostop2(sys_op2 + '.op2')
   seconct = {}
   j = 0
   for ind in (p['seconct'] == -1).nonzero()[0][::2]:
       seconct[p['seconct'][j]] = p['seconct'][j+8:ind][::2]
       j = ind + 2

   {101: array([     91,      92,      93, ..., 5907498, 5907499, 5907500], dtype=int32),
   102: array([1290001, 1290002, 1290003, ..., 1710100, 1710101, 1710102], dtype=int32),
   201: array([2000004, 2005283, 2005319, ..., 5924498, 5924499, 5924500], dtype=int32),
   609: array([7999031, 7999032, 7999033, ..., 9004098, 9004099, 9004100], dtype=int32)}

59. For 58 to be really useful, probably need to enhance
    calls to the drfuncs … would want access to other categories.
    Need some good ideas for this.
     o   Pass in the parent DR_Results … ?

     o Update drfunc arg list to enhance functionality:
    - now: drfunc(sol, nas, Vars, se)
    - new, after discussion with BTA:
      drfunc(sol, se_vars, event_data, user_arg) ... or something
      - event_data is a dict with potentially:
         - parent DR_Results
         - name
         - se
         - drmres SimpleNamespace
         - number of cases
         - current case
         - ? freq for psd functions?
         - nas
         - domain ("time", "freq")

63. mk_net_drms: output coord system could be input ...
    think of multiple ports

    - Having this internal would help because cglf could be formed
      in proper local coord system

    - actually, cglf is junk anyway isn't it? It would be computing
      based on the structure with the ports ... not the item attached
      to the port

    - but, ifatm and ifltm for the port would be nice ... probably

66. Write a nastran coordinate system plotter
    - use pyNastran instead?

67. Write a nastran node plotter
    - use pyNastran instead?

68. Add extreme histories to cla.DR_Results.form_extreme

69. Find or write a replacement for "mkruns"
    - Britney has something maybe for this ... ?

71. Implement compmat i think

73. Check into subspace iteration logic
    - Bathe K.J. The subspace iteration method – Revisited.
      Comput Struct (2012),
      http://dx.doi.org/10.1016/j.compstruc.2012.06.002

    - https://www-users.cs.umn.edu/~saad/PDF/ys-2014-1.pdf

74. Implement ERA algorithm

``75. Check out coverage for parallel processing
    o   Also, those if’s without an else … ? “Branch” testing.
    - unsuccessful on first attempt ... worth it?

76. Check manifest app

77. Accommodate ulvs, mugf and nothing … via a tag?
    - What about ‘drms’ and ‘nondrms’?
    - idea: instead of 'drms' and 'nondrms', use categories that
      specify which transform is to be used:
       - 'modes' (or 'phi' or 'ulvs' or ?)
       - 'resflex' (or 'g' or 'rf' or 'mugf' or ?)
       - 'none' (or 'other' or 'misc' or 'data' or ?)
    - from discussion with BTA, think about using, for example:
         acce = ltma
         velo = ltmv
         disp = ltmd
         forc = ltmf
       - probably wouldn't need to define a drfunc in this case!

84. if licensing is good, update guitools to Qt ... I think (this was
    nearly done i think ... just never finalized it because of license
    (see ~/python/gui/guitools_qt.py))

85. update the numpy docstring output to be current (right now, still
    using v 1.13)

87. Add "addcat" skeleton code generator?
    - goal is to make adding data recovery categories simpler

97. Add the “tf” class somewhere. Maybe ...
      o   After add “pade” …

98. datacursor.DC
    - add highlight_line option? Line would be plotted in a
      specifiable style when clicked (or hovered on?)
      o   Hmm, probably any time an annotation would be drawn
      o   Ability to turn off annotation might then be a desirable
          option

99. Add generator feature and hm features to Newmark-Beta solver

102. Fix up the sparse documentation for wtextseout

104. Add 'axis' option fftfilt, fftcoef (and others too probably)
     o make it elegant ... check dsp.exclusive_sgfilter to see if
       that's done well. Numpy must have nice functions for this since
       many of those functions allow it. Share code amongst these
       functions.

106. Add Henkel-Mar class -- I think. The one in
     python/workworks/henkelmar.py *might* be where to start.

107. Add more tutorials.
     - generator solver
     - force limiting
     - nonlinear spring analysis
     - cla

110. Consider refactoring the generator solvers by using “yield from”
     (can code be reused?)

`111. Consider refactoring large modules into small files
     o   Approach used in scipy:
         - make ode, cla, ... packages ... just like nastran is now
         - in the ode/__init__.py, imports could be, for example:
              from .solveunc import *
              from .solveexp2 import *
     - ode, cla refactored in v0.95.1

112. Can some things (ode solvers?) be sped up by numba?

124. cla.DR_Def, cla.DR_Results
     - Right now, there is no way to assure or confirm that a "psd"
       version of a data recovery function gets or was used ... hmm

129. Do the return values of rptpct1 make sense?

132. Units in mk_net_drms should be more settable (now, translation
     acceleration units is the only option)

134. mk_net_drms:

     ~ - The check below should be against the subset of b, if there
         is one
     - Also, the 123 vs 123456 should be a user option
     - With one grid, if it’s the reference, should we mess with
       formrbe3 at all???

        # use RBE3 for net accelerations
        if len(bset) > 6:
            dof_indep = 123
            xyz = ytools.mkpattvec([0, 1, 2], len(bset_if), 6).ravel()
            xyz = bset_if[xyz]
        else:
            dof_indep = 123456
            xyz = np.arange(6)

     - reorder is not efficient (fix mk_net_drms or cbreorder or
       both??)
        - if no reordering, just do nothing

     - grids should be from full uset … exception can happen otherwise
       because of a repeated grid id during the addgrid (pandas does
       not necessarily create delete old id’s from the index … it just
       doesn’t use them):

         grids = uset_if.index.get_level_values("id")[::6]
         new_id = grids.max() + 1
         uset2 = n2p.addgrid(uset_if, new_id, "b", 0, ref, 0)

136. Good solution for addgrid??:
     uset.index = uset.index.remove_unused_levels()

138. Switch testing to pytest. nosetests is not maintained apparently.
     - don't import nose for tests
     - this is probably not as big a job as it sounds ... nose tools
       aren't used that heavily I don't think (it's not tiny ...)

139. CLA cases should be able to have different time vectors/time steps
     - this *might* not be needed as it's pretty easy to just add
       a level to the DR_Results structure ...

146. The op4 writer wrote a bad file for the saocom high fidelity 1/3
     model ... debug this.
     - actually, this *might* have simply been a "formatted" vs
       "unformatted" op4 file

148. Make rdop2tload external? … now, have to do this:
     op2.OP2("PAF.op2").rdop2tload()

149. ytools load/save:
     - Add parameter to specify compression? (rather than relying on
       extension – which seems pretty restrictive)

150. In wtextseout, should have capability to write grids in non-basic
     coordinate system … makes moving the SE around later easier

152. Add wtcards ... write cards as read in by rdcards

153. ? Add "move_bulk_nodes" (or something):
     - it would use: bulk2uset, rdcards, replace_basic_cs, uset2bulk,
       wtcards
     - it would include option to sub new cs in relevant fields for
       different cards ... this would make it useable, but also hard
       to make it complete

157. Add ltma, ltmd = cb.modedisp_to_modeacce(m, k, bset, ltm)

159. Add “import_module” function to ytools?

162. In srs.vrs:
     ~ - Wording here: “The equation for Miles’ equation is:”
     ~ - Clean up calculation … (freq / fn) is done repeatedly
     - Add relative acceleration output?

         Uacce = p^4 / [(1-p^2)^2 + (2 zeta p)^2]  Zacce

163. psd.get_freq_oct should be able to return "book" values

164. locate.mat_intersect(ffn_dof_map[:, :2], ullage_tloads, keep=2)[0]
     - Add an “all” parameter or something … raise exception if not all
       found
     - Change default keep to be 2?

~165. Newmark beta solver doesn’t allow mass to be None?
    - v0.97.1

~166. Add column plotter
    - v0.97.3

~167. In docs, make links to numpy/scipy/etc functions live
    - v0.97.1

~168. Change beta to 14 in resample I think … try pts=5?? (see
     scipy.signal.kaiser)
    - v0.97.1

~169. Missing backslash in bulk.mkcomment docstr:
    - surround (bool; optional) – If True, a leading and trailing ‘$n’
      string will be added.
      - v0.97.2

~170. Update docs/tutorials/tools/nb_to_doc.py with black
      - v0.97.2

~171. Shouldn’t the rb and rf inputs to the solvers be allowed to be
     Boolean?
     - v0.97.3

172. update locate.find_rows to be more like mat_intersect is
     typically used and check for unique rows
      - this could use "findfirstandlast" routine
      - have two modes of output:
         - vector & error out on not found or if multiple found
         - list of lists, no erroring

        @numba.jit(nopython=True)
        def findfirstandlast(haystack, needle):
            left = 0
            right = haystack.size
            while left < right:
                mid = (left + right) // 2
                if needle > haystack[mid]:
                    left = mid + 1
                else:
                    right = mid
            while right < haystack.size and needle == haystack[right]:
                right += 1
            return left, right  # non-inclusive on the right
        
         
        def get_active_tloads_pv(rf_info, dofmap):
            dofmap = np.atleast_2d(dofmap)
            dofmap = dofmap[:, :2]
            # n = dofmap.shape[0]
         
            tloads = rf_info.rf_maps["tload"][:, 2:]
            haystack = tloads[:, 0] * 10 + tloads[:, 1]
            needles = dofmap[:, 0] * 10 + dofmap[:, 1]
         
            i = np.argsort(haystack, kind="stable")
            pv = []
            sorted_haystack = haystack[i]
            for needle in needles:
                first, last = findfirstandlast(sorted_haystack, needle)
                pv.append([i[j] for j in range(first, last)])
            return pv


~173. VRS should check for or enforce a good integration frequency vector

~174. Cbcheck should check for null rows and cols in BOTH mass and
     stiffness … not just mass, because there can be massless DOF on
     boundary (for example)

~175. From Dave H about uset documentation:

     You might consider [adding some] red formatting for your [uset]
     note in wtextseout, to make it jump off the page a little more?
     And also putting a warning in cbcheck similar to mk_net_drms
     might be helpful.

~176. Make a non statistical version of DR_Results.form_stat_ext(k)
 
    for sns in results.values():
        mx = sns.mx.max(axis=1)
        mn = sns.mn.min(axis=1)
        argmx = sns.mx.argmax(axis=1)
        argmn = sns.mn.argmin(axis=1)
        sns.ext = np.column_stack((mx, mn))
        cases = sns.cases
        sns.maxcase = [cases[i] for i in argmx]
        sns.mincase = [cases[i] for i in argmn]
        sns.ext_x = None  # time information is lost

        # handle SRS if it is there:
        if "srs" in sns.__dict__:
            for Q in sns.srs.srs:
                arr = sns.srs.srs[Q]
                sns.srs.ext[Q] = arr.max(axis=0)

~177. windowends is Tukey window … note this?

178. Incorporate BTA's nastran comments from
     pyyeti_comments-nastran.docx

179. Add check_for_fatal to mknast (like mkruns.cam has it)

180. Update mknast to be more generic and to create a Python script ?

~181. Document the Rayleigh peak factor in nice equations

~182. DR_Def.merge & DR_Event.add … add doc note about raising error on
     duplicate names

~183. Cbcheck: uset should say it’s for the b-set
